# Face-Recognition using MATLAB

## Overview

Face Recognition is a task that is trivial to humans under diâ†µerent lighting conditions, obstructions such as accessories, however, it has been a challenging task for a computer until the development of various face recognition techniques such as template matching and neural networks specifically CNNs. The current study employs three face recognition methods; Template matching, AlexNet and GoogLeNet. Image processing and augmentation was implemented and results showed that AlexNet outperformed the other methods. GoogLeNet did not produce robust results possibly due to the lack of large training dataset and the image quality which have been discussed. The paper provides a comparison and evaluation of the different recognition methods based on a relatively small face dataset.

## Dataset

A face database was provided with a total of 100 faces which contains multiple images from different subjects. The images were of the same size 600 x 600 in RGB channels. The training dataset consisted of one image per subject as the template and the test dataset had a total of 1344 images which were captured in different poses and lighting conditions. The training images on the dataset consisted of a single image captured in a certain pose and lighting of a subject corresponding to the several other poses in the test folder. The folders were part of the FaceDatabase directory. An evaluation code was used to test the accuracy of the algorithms. The true face IDs for the testing of the subjects was given in a MATLAB matrix and was loaded into the evaluation code. The aim of the program was to design two additional algorithms that would help classify the data. A baseline method involving cross correlation-based template matching was provided which had a baseline accuracy of approximately 25 percent.

## Algorithms

All programming was conducted on MATLAB and additional toolboxes for CNNs such as the deep learning toolbox and others were installed through MathWorks. Three types of algorithms were implemented. The baseline measure that was performed was based on a template matching recognition method. AlexNet was the second method that was implemented which utilised the Deep Learning Toolbox and lastly GoogLeNet was another CNN that was used to test for face recognition.

### Cross-Correlation Based Template Matching

All the images were retrieved, and the training images were converted from RGB to grayscale. To normalise the mean intensity value, the feature vectors were scaled through subtracting it by its mean value and dividing it by its standard deviation. The features of the training images were stored in a variable. Following the pre-processing, a for loop function was used to retrieve the test images one by one and the same method was performed. The cross-correlation values between the feature vectors of the test images and the training images were then calculated through dot product. The corresponding face label in the training set that has the highest cross correlation value was retrieved and saved for that test image.

### AlexNet 

Using the ImageDatastore object the training and the test images were loaded. A pretrained AlexNet neural network was loaded onto the program which was 8 layers deep with an input size of 227x227. All layers except the last three were extracted from the pretrained network since these layers help in classifying. The layers were then transferred to a classification task and was replaced by a fully connnected layer, a softmax layer and a classification output layer. The softmax layer outputs a probability distribution and it is generalisation of the logistic function that assures the output to fit between zero and one. Additionally, the image was augmented since the network requires image dimensions of 227x227x3 and the images used in the dataset has different sizes. This procedure is important to avoid overfitting of data as well as to ensure the features are accurately detected in the training images. Finally the training options were specified where the initial learning rate was set to 0.0001 and the max epochs was set to 6 and the network was then trained.

### GoogLeNet 

The initial steps of GoogLeNet is similar to AlexNet as the training and testing images were loaded into the ImageDatastore object. The pretrained GoogLeNet network was then loaded in MATLAB which has 22 layers and has an image input size of 224x224. The layer graph was then extracted from the trained network for plotting and the last three layers were replaced with a fully connected layer, a softmax layer and classification output layer. The last transferred layer was then connected to the new layers. Image augmentation was also executed since the network requires an input size of 224x224x3. Following the data augmentation, the training options were set where the minimum batch size was set to 10, maximum epochs were set to 6, the initial learning rate was set to 0.0001 and the validation frequency was set to 3. Upon setting the training parameters, the network was trained.


## Performance of the Algorithms 

The baseline cross correlation based template matching had a recognition accuracy of 25.3% and a training time of 32 seconds. AlexNet achieved a recognition accuracy of 32.2% with an approximate training time of 97 seconds with 60 iterations and 10 iterations per epoch. GoogLeNet scored a mere 8% accuracy in face recognition and a total training time of 132 seconds with similar iterations as AlexNet.

### AlexNet

AlexNet performed the best out of the three recognition methods for the current face recognition task. Since CNNs have in-built algorithms that uses the notable general matrix multiply, overlapping of pixels during the data moving through the network occurs which leads to an increased computation time. This is reflected in the current project where AlexNet took an approximate of a 100 seconds to finish training and testing. Additionally, one of the primary tests of such deep learning models was that it was performed on the ImageNet database which comprised of over a million images with around 1000 categories of high definition photos. However, the face dataset used in the current study comprised of photos that have various exposures, inconsistent sharpness and blurriness in the image, noise, contrast and others which is one of the reasons the current implementation could not achieve a higher accuracy although it outperformed the other two algorithms. The examples of such noise and blurriness can be seen in the dataset. Through strides and max pooling layers, the rapid downsampling of images occurs in AlexNet where the last convolutional layer is shaped into a vector and used as the input for the fully connected layers. The presence of noise in the image database is one of the reasons that hindered AlexNets performance as lower levels of noise has been found in previous literature to assure verifiable performance. 

## Conclusions and Future Directions

In conclusion, the aim of the research was to postulate face recognition algorithms that could effectively recognise faces on a dataset of 1344 images. Out of the three algorithms, AlexNet outperformed template matching and GoogLeNet. GoogLeNet did not perform as well as expected due to its reliance on image quality as well as the necessity of a much larger data for better performance. Given the architecture of such neural networks, deep learning models can be fine tuned to provide robust results. It is expected that GoogLeNet would perform significantly better given a larger training dataset regardless of the poor image qualities. However, it is important to note that one shot learning for face recognition especially given a small dataset would be ideal over CNNs and implementation of Siamese Network could potentially outperform both CNNs utilised in this project.
